{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name:\n",
    "\n",
    "Student ID: 314551808\n",
    "\n",
    "GitHub ID: AndiSeepferdchen\n",
    "\n",
    "Kaggle name: Andreas Flatscher\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![pic_ranking.png](./Lab2_Phase3/Screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "\n",
    "The preprocessing simply combined the files data_identification.csv, emotion.csv and final_posts.json into two pandas dataframes, train_df and test_df. We saved them and uploaded them to the server where the jupyter notebook did the model trainig. We have combined the texts and hashtags into one whole string, for simplicity.\n",
    "### 1.2 Feature Engineering Steps\n",
    "\n",
    "No further feature engineering steps were done.\n",
    "### 1.3 Explanation of Your Model\n",
    "\n",
    "For the model, I have chosen Falcon3b-base, a pretrained LLM, with an additional classification layer to get an output. I have trained the model on the train set for only two epochs, since training took a long time and time was short. This has resulted in an test accuracy of 0.46. It can be speculated, that training for more epochs significantly increases the accuracy.\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "**Add more detail in previous sections**\n",
    "\n",
    "### 2.1 Mention Different Things You Tried\n",
    "\n",
    "[Content for Experiments]\n",
    "\n",
    "### 2.2 Mention Insights You Gained\n",
    "Training LLMs, even small ones, requires much resources. A GPU space of about 16GB was used and trained for multiple hours. It is sad that I could not train for longer, since I think it would have resulted in good accuracy, since the task is a simple context-based and LLMs usually perform good in reading context out of text.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "os.chdir(os.path.dirname(__file__))\n",
    "\n",
    "id_df = pd.read_csv(\"./data_identification.csv\")\n",
    "emotion_df = pd.read_csv(\"./emotion.csv\")\n",
    "posts = []\n",
    "\n",
    "with open(\"final_posts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "records = []\n",
    "for item in data:\n",
    "    post = item.get(\"root\", {}).get(\"_source\", {}).get(\"post\", {})\n",
    "    if post:\n",
    "        records.append({\n",
    "            \"id\": post.get(\"post_id\"),\n",
    "            \"texts\": post.get(\"text\"),\n",
    "            \"hashtags\": post.get(\"hashtags\")\n",
    "        })\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "posts_df = pd.DataFrame(records, columns=[\"id\", \"texts\", \"hashtags\"])\n",
    "print(posts_df)\n",
    "\n",
    "posts_df[\"texts\"] = posts_df.apply(lambda row: row[\"texts\"] + \" \" + \" \".join(row[\"hashtags\"]) if row[\"hashtags\"] else row[\"texts\"], axis=1)\n",
    "\n",
    "# Drop the hashtags column\n",
    "posts_df = posts_df.drop(columns=[\"hashtags\"])\n",
    "\n",
    "print(posts_df)\n",
    "\n",
    "df_combined = pd.merge(posts_df, emotion_df, on=\"id\", how=\"left\")\n",
    "#df_combined = df_combined.dropna(subset=[\"emotion\"])\n",
    "\n",
    "\n",
    "df_combined = pd.merge(df_combined, id_df, on=\"id\", how=\"left\")\n",
    "df_combined = df_combined.dropna(subset=[\"split\"])\n",
    "print(df_combined)\n",
    "\n",
    "\n",
    "invalid_splits = df_combined[~df_combined[\"split\"].isin([\"train\", \"test\"])]\n",
    "\n",
    "# Check if any exist\n",
    "if not invalid_splits.empty:\n",
    "    print(\"Invalid split values found:\")\n",
    "    print(invalid_splits)\n",
    "else:\n",
    "    print(\"All split values are valid.\")\n",
    "\n",
    "df_train = df_combined[df_combined[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "print(df_train)\n",
    "# Test DataFrame\n",
    "df_test = df_combined[df_combined[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "print(df_test)\n",
    "df_train = df_train.drop(columns=[\"split\"])\n",
    "df_test = df_test.drop(columns=[\"split\"])\n",
    "# Save train DataFrame\n",
    "df_train.to_csv(\"train.csv\", index=False)\n",
    "\n",
    "# Save test DataFrame\n",
    "df_test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install -q transformers evaluate accelerate\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1,2,3'\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 1. Load dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")  # or \"test.csv\"\n",
    "df_test = pd.read_csv(\"test.csv\")  # or \"test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'anger': 0, 'disgust': 1, 'fear': 2, 'sadness': 3, 'surprise': 4, 'joy': 5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2137f4b71f48470d875312a08e1f92d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47890 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d452f2f6ae34800a9a9c6bbeb81f940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16281 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "model_name = \"tiiuae/Falcon3-3B-Base\"  # Falcon-7b model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "# Define label mapping\n",
    "label_list = [\"anger\", \"disgust\", \"fear\", \"sadness\", \"surprise\", \"joy\"]  # order can be arbitrary\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(\"Label mapping:\", label2id)\n",
    "\n",
    "def preprocess_train(batch):\n",
    "    texts = batch[\"texts\"]\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    enc[\"labels\"] = [label2id[lbl] for lbl in batch[\"emotion\"]]\n",
    "    return enc\n",
    "\n",
    "def preprocess_test(batch):\n",
    "    texts = batch[\"texts\"]\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # No labels for test set\n",
    "    return enc\n",
    "\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"test\": Dataset.from_pandas(df_test)\n",
    "})\n",
    "\n",
    "# Tokenize separately\n",
    "tokenized_train = dataset_dict[\"train\"].map(\n",
    "    preprocess_train,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict[\"train\"].column_names\n",
    ")\n",
    "\n",
    "tokenized_test = dataset_dict[\"test\"].map(\n",
    "    preprocess_test,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict[\"test\"].column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger: 10694 examples\n",
      "disgust: 1183 examples\n",
      "fear: 2009 examples\n",
      "sadness: 3926 examples\n",
      "surprise: 6281 examples\n",
      "joy: 23797 examples\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten the list of labels from the dataset\n",
    "all_labels = [label2id[lbl] for lbl in dataset_dict[\"train\"][\"emotion\"]]\n",
    "\n",
    "# Count occurrences\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "# Print counts for each label\n",
    "for i, label in id2label.items():\n",
    "    print(f\"{label}: {label_counts.get(i, 0)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.4.1+cu121\n",
      "Compiled CUDA: 12.1\n",
      "Runtime available: True\n",
      "/workplace/zyxu/miniconda3/envs/LLM_1/lib/python3.8/site-packages/torch/utils/_pytree.py\n",
      "['Any', 'BUILTIN_TYPES', 'Callable', 'Context', 'DEFAULT_TREESPEC_SERIALIZATION_PROTOCOL', 'DefaultDict', 'Deque', 'Dict', 'DumpableContext', 'FlattenFunc', 'FlattenWithKeysFunc', 'Fn', 'Fn2', 'Fn3', 'FnAny', 'FromDumpableContextFn', 'FrozenSet', 'Generic', 'GenericOrderedDict', 'GetAttrKey', 'Hashable', 'Iterable', 'K', 'KeyEntry', 'KeyPath', 'LeafSpec', 'List', 'MapOnlyFn', 'Mapping', 'MappingKey', 'MaybeFromStrFunc', 'NO_SERIALIZED_TYPE_NAME_FOUND', 'NamedTuple', 'NodeDef', 'Optional', 'OrderedDict', 'Protocol', 'PyTree', 'R', 'S', 'SERIALIZED_TYPE_TO_PYTHON_TYPE', 'STANDARD_DICT_TYPES', 'SUPPORTED_NODES', 'SUPPORTED_SERIALIZED_TYPES', 'Sequence', 'SequenceKey', 'T', 'ToDumpableContextFn', 'ToStrFunc', 'TreeSpec', 'Tuple', 'Type', 'Type2', 'Type3', 'TypeAny', 'TypeVar', 'U', 'UnflattenFunc', 'Union', '_DummyLeaf', '_LEAF_SPEC', '_NODE_REGISTRY_LOCK', '_ProtocolFn', '_SUPPORTED_PROTOCOLS', '_SerializeNodeDef', '_TreeSpecSchema', '__all__', '__annotations__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_broadcast_to_and_flatten', '_defaultdict_deserialize', '_defaultdict_flatten', '_defaultdict_flatten_with_keys', '_defaultdict_serialize', '_defaultdict_unflatten', '_deque_flatten', '_deque_flatten_with_keys', '_deque_unflatten', '_dict_flatten', '_dict_flatten_with_keys', '_dict_unflatten', '_generate_key_paths', '_get_node_type', '_is_leaf', '_is_namedtuple_instance', '_json_to_treespec', '_list_flatten', '_list_flatten_with_keys', '_list_unflatten', '_namedtuple_deserialize', '_namedtuple_flatten', '_namedtuple_flatten_with_keys', '_namedtuple_serialize', '_namedtuple_unflatten', '_odict_flatten', '_odict_unflatten', '_ordereddict_flatten', '_ordereddict_flatten_with_keys', '_ordereddict_unflatten', '_private_register_pytree_node', '_register_namedtuple', '_register_pytree_node', '_tree_flatten_helper', '_treespec_to_json', '_tuple_flatten', '_tuple_flatten_with_keys', '_tuple_unflatten', 'arg_tree_leaves', 'cast', 'dataclasses', 'defaultdict', 'deprecated', 'deque', 'functools', 'importlib', 'json', 'key_get', 'keystr', 'map_only', 'namedtuple', 'overload', 'pytree_to_str', 'register_pytree_node', 'str_to_pytree', 'sys', 'threading', 'tree_all', 'tree_all_only', 'tree_any', 'tree_any_only', 'tree_flatten', 'tree_flatten_with_path', 'tree_iter', 'tree_leaves', 'tree_leaves_with_path', 'tree_map', 'tree_map_', 'tree_map_only', 'tree_map_only_', 'tree_map_with_path', 'tree_structure', 'tree_unflatten', 'treespec_dumps', 'treespec_loads', 'treespec_pprint', 'types', 'warnings']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Compiled CUDA:\", torch.version.cuda)\n",
    "print(\"Runtime available:\", torch.cuda.is_available())\n",
    "\n",
    "import torch.utils._pytree as pytree\n",
    "print(pytree.__file__)\n",
    "print(dir(pytree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES: 0,1,2,3\n",
      "torch.cuda.device_count(): 4\n",
      "0 NVIDIA RTX A4000\n",
      "1 NVIDIA RTX A4000\n",
      "2 NVIDIA RTX A4000\n",
      "3 NVIDIA RTX A4000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a7d59f6c6c40659bcb9dc00dc09c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "print(\"torch.cuda.device_count():\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(i, torch.cuda.get_device_name(i))\n",
    "\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "def prepare_model_for_training(model):\n",
    "    model.gradient_checkpointing_disable()\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],  # Correct for Falcon3\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"  # Change to \"SEQ_CLS\" if doing classification\n",
    "    )\n",
    "\n",
    "    return get_peft_model(model, config)\n",
    "    \n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n",
    "from transformers import DataCollatorWithPadding, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "num_labels = len(set(dataset_dict[\"train\"][\"emotion\"]))\n",
    "\n",
    "# --- Add classification head ---\n",
    "class FalconWithClassifier(nn.Module):\n",
    "    def __init__(self, base_model, num_labels):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.base_model.gradient_checkpointing_enable()\n",
    "        hidden_size = base_model.config.hidden_size  # 4544 for Falcon-7B\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels).to(base_model.device)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        # Remove labels from kwargs\n",
    "        kwargs.pop(\"labels\", None)\n",
    "\n",
    "        # Get base model outputs, ask for hidden states\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # FalconForCausalLM returns a tuple: hidden_states[-1] is last layer\n",
    "        hidden_states = outputs.hidden_states[-1]  # [batch, seq, hidden]\n",
    "        pooled = hidden_states[:, -1, :]           # take last token\n",
    "        logits = self.classifier(self.dropout(pooled))\n",
    "\n",
    "        return {\"logits\": logits}\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3622918 || all params: 3231278086 || trainable%: 0.11212027883631678\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from datetime import datetime\n",
    "from accelerate import Accelerator\n",
    "\n",
    "\n",
    "accelerator = Accelerator(mixed_precision=\"bf16\")\n",
    "\n",
    "base_model = prepare_model_for_training(model)\n",
    "\n",
    "# --- Wrap with classifier ---\n",
    "model = FalconWithClassifier(base_model, num_labels=num_labels)\n",
    "\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "# --- Optimizer ---\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "model, optimizer = accelerator.prepare(model, optimizer)\n",
    "\n",
    "\n",
    "training_args = {\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"fp16\": True,\n",
    "    \"save_total_limit\": 4,\n",
    "    \"logging_steps\": 25,\n",
    "    \"output_dir\": \"output_dir\",  # give the location where you want to store checkpoints\n",
    "    \"save_strategy\": 'epoch',\n",
    "    \"optim\": \"paged_adamw_8bit\",\n",
    "    \"lr_scheduler_type\": 'cosine',\n",
    "    \"warmup_ratio\": 0.05,\n",
    "    \"per_device_train_batch_size\": 1,  # Adjust based on your GPU memory\n",
    "    # \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2395/2395 [1:33:17<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train loss: 0.0880\n",
      "Validation accuracy: 50.08%\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2395/2395 [1:21:31<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train loss: 0.0795\n",
      "Validation accuracy: 55.20%\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from accelerate import Accelerator\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "num_epochs = 2\n",
    "batch_size = 256\n",
    "grad_accum_steps = 16\n",
    "lr = 2e-5\n",
    "\n",
    "# âœ… Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "# âœ… Let accelerate handle device placement for *everything*\n",
    "model, optimizer = accelerator.prepare(\n",
    "    model, optimizer\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "splits = list(kf.split(range(len(tokenized_train))))  # use range(n), not the dataset itself\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Determine which fold to use this epoch (cycle through 0â€“4)\n",
    "    fold_idx = epoch % len(splits)\n",
    "    train_idx, test_idx = splits[fold_idx]\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "\n",
    "     \n",
    "    train_dataset = tokenized_train.select(train_idx)\n",
    "    eval_dataset = tokenized_train.select(test_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=1, collate_fn=data_collator)\n",
    "\n",
    "    train_loader, eval_loader = accelerator.prepare(train_loader, eval_loader)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    # ðŸ”¹ Training loop\n",
    "    for step, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n",
    "        if batch[\"input_ids\"].numel() == 0 or batch[\"labels\"].numel() == 0:\n",
    "            print(\"SKIPPED\")\n",
    "            continue  # skip malformed batch\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs\n",
    "        if isinstance(outputs, dict):\n",
    "            logits = outputs[\"logits\"]\n",
    "        else:\n",
    "            logits = outputs  # fallback if model returns tensor directly\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        loss = loss / grad_accum_steps\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        if (step + 1) % grad_accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        accelerator.wait_for_everyone()\n",
    "        save_path = f\"./task_1_falcon7b_{epoch}\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        # Save base Falcon model using Hugging Face API\n",
    "        model.base_model.save_pretrained(os.path.join(save_path, \"base_model\"), save_safetensors=True)\n",
    "        # Save tokenizer\n",
    "        tokenizer.save_pretrained(os.path.join(save_path, \"tokenizer\"))\n",
    "        # Save your custom classifier head weights\n",
    "        torch.save(model.classifier.state_dict(), os.path.join(save_path, \"classifier.pt\"))\n",
    "    \n",
    "    accelerator.print(f\"Epoch {epoch+1} | Train loss: {total_loss/len(train_loader):.4f}\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    # ðŸ”¹ Evaluation loop\n",
    "    for batch in eval_loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.get(\"logits\", outputs)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            correct = correct + (preds == batch[\"labels\"]).sum().item()\n",
    "            total = total + 1\n",
    "    accelerator.print(f\"Validation accuracy: {100*correct/total:.2f}%\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataLoader\n",
    "test_loader = DataLoader(tokenized_test, batch_size=16, collate_fn=data_collator)\n",
    "test_loader = accelerator.prepare(test_loader)\n",
    "\n",
    "model.eval()\n",
    "preds_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.get(\"logits\", outputs)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        preds_all.extend(preds.cpu().numpy())\n",
    "\n",
    "# Map predicted ids to labels\n",
    "pred_labels = [id2label[i] for i in preds_all]\n",
    "\n",
    "# Save predictions as CSV\n",
    "df_pred = pd.DataFrame({\n",
    "    \"id\": df_test[\"id\"],       # assuming df_test contains the original test IDs\n",
    "    \"emotion\": pred_labels\n",
    "})\n",
    "\n",
    "df_pred.to_csv(\"pred.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2025-Lab2-Exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
